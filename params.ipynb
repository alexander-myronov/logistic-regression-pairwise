{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file, make_circles\n",
    "\n",
    "\n",
    "from links import LinksClassifier\n",
    "from logit import LogisticRegressionPairwise, LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from new_experiment_runner.cacher import CSVCacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = pd.read_csv('data/params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = pd.read_csv('data/params_big.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_scores(ax, scores, vmin, vmax, range_x, range_y):\n",
    "    r = ax.imshow(scores, \n",
    "        interpolation='nearest',\n",
    "                  cmap=plt.cm.hot,\n",
    "                  vmax=vmax,\n",
    "                  vmin=vmin,\n",
    "                origin='lower')\n",
    "    ax.set_xticks(np.arange(len(range_x)))\n",
    "    ax.set_xticklabels(range_x)\n",
    "    ax.set_yticks(np.arange(len(range_y)))\n",
    "    ax.set_yticklabels(range_y)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'cv_split', u'gs_test_size', u'cv_splits', u'cv_test_size',\n",
       "       u'percent_unlabeled', u'percent_links', u'dataset', u'beta', u'delta',\n",
       "       u'cv_random_state', u'gs_splits', u'percent_labels', u'alpha',\n",
       "       u'cv_score', u'gamma', u'test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets =params.dataset.unique()\n",
    "fig, ax = plt.subplots(ncols=len(datasets)/2, nrows=2)\n",
    "ax= ax.flatten()\n",
    "\n",
    "for i, ds in enumerate(datasets):\n",
    "    ds_params = params.ix[params['dataset'] == ds]\n",
    "    ds_score_grouped = pd.groupby(ds_params, by=['beta', 'delta']).agg({'test_score':np.mean})\n",
    "    ds_score_grouped = ds_score_grouped.unstack(level=-1)\n",
    "    \n",
    "    r = plot_scores(ax[i], ds_score_grouped, vmin=0.0, vmax=1, range_y=np.sort(ds_params.beta.unique()),\n",
    "                range_x=np.sort(ds_params.delta.unique()))\n",
    "    \n",
    "    ax[i].set_xlabel('delta')\n",
    "    ax[i].set_ylabel('beta')\n",
    "    ax[i].set_title(ds)\n",
    "    labels = ax[i].get_xticklabels() \n",
    "    plt.setp(labels, rotation=45, fontsize=10) \n",
    "    \n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(r, cax=cbar_ax)\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tradeoff = pd.read_csv('data/tradeoff_trzmiel2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets =tradeoff.dataset.unique()\n",
    "fig, ax = plt.subplots(ncols=len(datasets)/2, nrows=2)\n",
    "ax= ax.flatten()\n",
    "\n",
    "for i, ds in enumerate(datasets):\n",
    "    ds_params = tradeoff.ix[tradeoff['dataset'] == ds]\n",
    "    ds_score_grouped = pd.groupby(ds_params, by=['percent_labels', 'percent_links']).agg({'test_score':np.mean})\n",
    "    ds_score_grouped = ds_score_grouped.unstack(level=-1)\n",
    "    \n",
    "    r = plot_scores(ax[i], ds_score_grouped, vmin=ds_params.test_score.min(), vmax=1,\n",
    "                    range_y=np.round(np.sort(ds_params.percent_labels.unique()), 2),\n",
    "                    range_x=np.round(np.sort(ds_params.percent_links.unique()), 2))\n",
    "    \n",
    "    ax[i].set_xlabel('% links')\n",
    "    ax[i].set_ylabel('% labels')\n",
    "    ax[i].set_title(ds)\n",
    "    labels = ax[i].get_xticklabels() \n",
    "    plt.setp(labels, rotation=45, fontsize=10) \n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(r, cax=cbar_ax)\n",
    "fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, y, percent_labels, percent_links, percent_unlabeled, random_state=42):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    #X = X.toarray()\n",
    "\n",
    "    choice1 = next(StratifiedShuffleSplit(n_splits=1, train_size=percent_links).split(X, y))[0]\n",
    "    choice1 = np.in1d(np.arange(len(y)), choice1)\n",
    "\n",
    "    choice2 = next(StratifiedShuffleSplit(n_splits=1, train_size=percent_links).split(X, y))[0]\n",
    "    choice2 = np.in1d(np.arange(len(y)), choice2)\n",
    "\n",
    "    z = (y[choice1] == y[choice2]).astype(float)\n",
    "\n",
    "    links_index = choice1 | choice2\n",
    "    # print(links_index.sum())\n",
    "\n",
    "\n",
    "    if percent_labels < 1:\n",
    "        not_links_where = np.where(~links_index)[0]\n",
    "        labels_choice = next(StratifiedShuffleSplit(n_splits=1,\n",
    "                                                    train_size=int(percent_labels * len(y))).split(\n",
    "            X[not_links_where], y[not_links_where]))[0]\n",
    "\n",
    "        # print(not_links_where.shape)\n",
    "        labels_choice = not_links_where[labels_choice]\n",
    "    else:\n",
    "        raise Exception()\n",
    "        # labels_choice = np.arange(0, len(X))\n",
    "    labels_index = np.in1d(np.arange(len(y)), labels_choice)\n",
    "\n",
    "    unsup_index = ~(labels_index & links_index)\n",
    "    unsup_where = np.where(unsup_index)[0]\n",
    "    unsup_choice = np.random.choice(unsup_where, size=int(percent_unlabeled * len(y)),\n",
    "                                    replace=False)\n",
    "\n",
    "    # print(labels_index.sum(), links_index.sum(), unsup_index.sum())\n",
    "    assert (labels_index | links_index | unsup_index).sum() == len(y)\n",
    "\n",
    "    return labels_index, choice1, choice2, unsup_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from logit import LogisticRegressionPairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import matplotlib.cm\n",
    "X, y = make_moons(400, noise=0.2)\n",
    "#y[y==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x199c6748>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(X)\n",
    "alpha=0.1\n",
    "gamma=2.5\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3)\n",
    "plt.tight_layout()\n",
    "\n",
    "labels, links1, links2, unsup = split_dataset(X, y, percent_labels=0.1, percent_links=0.05, percent_unlabeled=0.1)\n",
    "z = (y[links1] == y[links2]).astype(int)\n",
    "\n",
    "h = 0.1\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "pos_labels=y == 1\n",
    "ax[0].scatter(X[pos_labels][:, 0], X[pos_labels][:, 1], c='#0000FF',  label='positive samples')\n",
    "ax[0].scatter(X[~pos_labels][:, 0], X[~pos_labels][:, 1], c='#FF0000', label='negative samples')\n",
    "\n",
    "\n",
    "ax[0].legend(loc=3, prop={'size':9})\n",
    "ax[0].set_title('Log. reg. on full dataset')\n",
    "\n",
    "ax[0].set_xlim(xx.min(), xx.max())\n",
    "ax[0].set_ylim(yy.min(), yy.max())\n",
    "ax[0].set_xticks(())\n",
    "ax[0].set_yticks(())\n",
    "\n",
    "estimator0 = LogisticRegression(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "estimator0.fit(X, y)\n",
    "Z0 = estimator0.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z0 = Z0.reshape(xx.shape)\n",
    "ax[0].contourf(xx, yy, Z0, cmap=cm, alpha=.35, levels=np.linspace(0, 1, 20))\n",
    "\n",
    "pos_labels=y[labels] == 1\n",
    "ax[1].scatter(X[labels][pos_labels][:, 0], X[labels][pos_labels][:, 1], c='#0000FF',  label='positive samples')\n",
    "ax[1].scatter(X[labels][~pos_labels][:, 0], X[labels][~pos_labels][:, 1], c='#FF0000', label='negative samples')\n",
    "pos_labels=y[~labels] == 1\n",
    "ax[1].scatter(X[~labels][pos_labels][:, 0], X[~labels][pos_labels][:, 1], c='#0000FF', alpha=0.3)\n",
    "ax[1].scatter(X[~labels][~pos_labels][:, 0], X[~labels][~pos_labels][:, 1], c='#FF0000', alpha=0.3)\n",
    "\n",
    "ax[1].legend(loc=3, prop={'size':9})\n",
    "ax[1].set_title('Log. reg. on labeled part')\n",
    "\n",
    "ax[1].set_xlim(xx.min(), xx.max())\n",
    "ax[1].set_ylim(yy.min(), yy.max())\n",
    "ax[1].set_xticks(())\n",
    "ax[1].set_yticks(())\n",
    "\n",
    "estimator1 = LogisticRegression(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "\n",
    "estimator1.fit(X[labels], y[labels])\n",
    "Z1 = estimator1.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z1 = Z1.reshape(xx.shape)\n",
    "ax[1].contourf(xx, yy, Z1, cmap=cm, alpha=.35, levels=np.linspace(0, 1, 20))\n",
    "\n",
    "\n",
    "# just plot the dataset first\n",
    "\n",
    "\n",
    "\n",
    "pos_labels=y[labels] == 1\n",
    "#ind = np.zeros(len(y))\n",
    "\n",
    "ax[2].plot([], [], 'g:', label='must-link')\n",
    "ax[2].plot([], [], 'r--', label='cannot-link')\n",
    "\n",
    "# Pot the training points\n",
    "ax[2].scatter(X[labels][pos_labels][:, 0], X[labels][pos_labels][:, 1], c='#0000FF',  label='positive samples')\n",
    "ax[2].scatter(X[labels][~pos_labels][:, 0], X[labels][~pos_labels][:, 1], c='#FF0000', label='negative samples')\n",
    "\n",
    "# and testing points\n",
    "ax[2].scatter(X[links1][:, 0], X[links1][:, 1], c='green', cmap=cm_bright, alpha=1, marker='o', label='linked samples')\n",
    "ax[2].scatter(X[links2][:, 0], X[links2][:, 1], c='green', cmap=cm_bright, alpha=1, marker='o')\n",
    "ax[2].scatter(X[unsup][:, 0], X[unsup][:, 1], c='black', cmap=cm_bright, marker='x', label='unlabeled samples')\n",
    "ax[2].scatter(X[~labels][:, 0], X[~labels][:, 1],c=y[~labels], cmap=cm, alpha=0.2)\n",
    "\n",
    "for i in xrange(len(z)):\n",
    "    ax[2].plot([X[links1][i, 0], X[links2][i, 0]], [X[links1][i, 1], X[links2][i, 1]], 'g-' if z[i] else 'r--', alpha=0.5)\n",
    "\n",
    "    \n",
    "# blue_line = mlines.Line2D([], [], color='blue', marker='*',\n",
    "#                           markersize=15, label='Blue stars')\n",
    "\n",
    "l_handles, l_labels = ax[2].get_legend_handles_labels()\n",
    "order = np.arange(len(l_labels))\n",
    "\n",
    "\n",
    "\n",
    "l_handles = [x for (o,x) in sorted(zip(order,l_handles))]\n",
    "l_labels = [x for (o,x) in sorted(zip(order,l_labels))]\n",
    "\n",
    "\n",
    "ax[2].legend(handles=l_handles, labels=l_labels, loc=3, prop={'size':9})\n",
    "ax[2].set_title('Log. reg. with links and unlabeled')\n",
    "\n",
    "ax[2].set_xlim(xx.min(), xx.max())\n",
    "ax[2].set_ylim(yy.min(), yy.max())\n",
    "ax[2].set_xticks(())\n",
    "ax[2].set_yticks(())\n",
    "\n",
    "estimator2 = LinksClassifier(alpha=10, kernel='rbf',gamma=gamma, solver='tnc', beta=500, delta=20)\n",
    "estimator2.fit(X[labels], y[labels], X1=X[links1], X2=X[links2], z=z, Xu=X[unsup])\n",
    "# score = estimator.score(X_test, y_test)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "Z = estimator2.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax[2].contourf(xx, yy, Z, cmap=cm, alpha=.35, levels=np.linspace(0, 1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[unsup]), len(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
